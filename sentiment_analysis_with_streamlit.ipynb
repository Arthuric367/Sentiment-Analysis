'''
2025/8/1 - Train MultiNomialNB ensemble with LinearSVC and Logistic Regression
Test 3:
- increase vectorizer max_features=15000 with trigrams
- Increase KBest=8000

Runtime: 84.7s

Result:
Best Naive Bayes Parameters: {'alpha': np.float64(0.0017787658410143284), 'fit_prior': False}
Best Naive Bayes Cross-Validation Accuracy: 0.88
Best LinearSVC Parameters: {'C': np.float64(0.5908361216819946)}
Best LinearSVC Cross-Validation Accuracy: 0.90
Best Logistic Regression Parameters: {'C': np.float64(3.7554011884736247)}
Best Logistic Regression Cross-Validation Accuracy: 0.90
Ensemble Test Accuracy: 0.90
**TP/TF higher than test 2.

Action:
Update ipynb for MultiNomialNB ensemble model with tunning v1.0.25

'''
# Cell 1: Install required libraries
!pip install streamlit pyngrok pandas numpy scikit-learn nltk seaborn matplotlib -q
#!wget -q https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz
!tar -xvzf ngrok-v3-stable-linux-amd64.tgz -C /usr/local/bin
!chmod +x /usr/local/bin/ngrok

# Cell 2: Train Ensemble with Naive Bayes, LinearSVC, and Logistic Regression
import pandas as pd
import nltk
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.ensemble import VotingClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import LinearSVC
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.feature_selection import SelectKBest, chi2
from nltk.corpus import stopwords
import seaborn as sns
import matplotlib.pyplot as plt
import pickle
from scipy.stats import uniform

# Reinstall nltk to ensure clean setup
!pip install nltk --force-reinstall -q
nltk.download('stopwords')

# Load data
data = pd.read_csv('/content/sample_data/IMDB Dataset.csv')
reviews = data['review']
labels = data['sentiment']  # 'negative' or 'positive'

# Preprocess text
stop_words = set(stopwords.words('english'))
def preprocess(text):
    return ' '.join(word.lower() for word in text.split() if word.lower() not in stop_words)
reviews = reviews.apply(preprocess)

# Convert text to numerical features with bigrams
vectorizer = TfidfVectorizer(max_features=15000, ngram_range=(1, 3))
X = vectorizer.fit_transform(reviews)
y = labels

# Feature selection
selector = SelectKBest(chi2, k=8000)
X = selector.fit_transform(X, y)

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

'''
Disable to check performance of apply all data
# Use subset for tuning -
subset_size = 10000
X_train_subset = X_train[:subset_size]
y_train_subset = y_train[:subset_size]
'''

# Tune Multinomial Naive Bayes
param_dist = {
    'alpha': uniform(0.001, 1.0),
    'fit_prior': [True, False]
}
grid = RandomizedSearchCV(MultinomialNB(), param_dist, n_iter=20, cv=5, n_jobs=-1, random_state=42)
grid.fit(X_train, y_train)
print(f"Best Naive Bayes Parameters: {grid.best_params_}")
print(f"Best Naive Bayes Cross-Validation Accuracy: {grid.best_score_:.2f}")

# Tune LinearSVC & Logistic Regression model
param_dist_svm = {'C': uniform(0.01, 10)}
grid_svm = RandomizedSearchCV(LinearSVC(max_iter=2000), param_dist_svm, n_iter=10, cv=5, n_jobs=-1, random_state=42)
grid_svm.fit(X_train, y_train)
svm = grid_svm.best_estimator_
param_dist_lr = {'C': uniform(0.01, 10)}
grid_lr = RandomizedSearchCV(LogisticRegression(max_iter=2000), param_dist_lr, n_iter=10, cv=5, n_jobs=-1, random_state=42)
grid_lr.fit(X_train, y_train)
lr = grid_lr.best_estimator_
print(f"Best LinearSVC Parameters: {grid_svm.best_params_}")
print(f"Best LinearSVC Cross-Validation Accuracy: {grid_svm.best_score_:.2f}")
print(f"Best Logistic Regression Parameters: {grid_lr.best_params_}")
print(f"Best Logistic Regression Cross-Validation Accuracy: {grid_lr.best_score_:.2f}")

# Train ensemble model
nb = MultinomialNB(alpha=grid.best_params_['alpha'], fit_prior=grid.best_params_['fit_prior'])
svm = LinearSVC(C=0.1, max_iter=2000)  # No probabilities, so use SVC with probability
lr = LogisticRegression(C=1, max_iter=2000)
ensemble = VotingClassifier(estimators=[('nb', nb), ('svm', svm), ('lr', lr)], voting='hard')
ensemble.fit(X_train, y_train)
predictions = ensemble.predict(X_test)
print(f"Ensemble Test Accuracy: {accuracy_score(y_test, predictions):.2f}")

# Save ensemble model
model = ensemble
model.fit(X_train, y_train)

# Show confusion matrix for ensemble
cm = confusion_matrix(y_test, predictions)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Ensemble Confusion Matrix')
plt.show()

# Predict on new text
new_text = ["This movie was amazing!"]
new_text_transformed = selector.transform(vectorizer.transform(new_text))
print(f"Prediction for sample text: {model.predict(new_text_transformed)[0]}")

# Save model, vectorizer, and selector
with open('model.pkl', 'wb') as f:
    pickle.dump(model, f)
with open('vectorizer.pkl', 'wb') as f:
    pickle.dump(vectorizer, f)
with open('selector.pkl', 'wb') as f:
    pickle.dump(selector, f)

# Cell 3: Write Streamlit app
app_code = """
import streamlit as st
import pickle
import nltk
from nltk.corpus import stopwords
import string

nltk.download('stopwords')
stop_words = set(stopwords.words('english'))

with open('model.pkl', 'rb') as f:
    model = pickle.load(f)
with open('vectorizer.pkl', 'rb') as f:
    vectorizer = pickle.load(f)
with open('selector.pkl', 'rb') as f:
    selector = pickle.load(f)

def preprocess(text):
    text = text.lower()
    text = ''.join([char for char in text if char not in string.punctuation])
    text = ' '.join(word for word in text.split() if word not in stop_words)
    return text

st.title("Movie Review Sentiment Analysis")
st.write("Enter a movie review to predict its sentiment (positive or negative).")

user_input = st.text_area("Enter your review:", "Type your movie review here...")
if st.button("Predict Sentiment"):
    if user_input:
        processed_input = preprocess(user_input)
        input_vector = selector.transform(vectorizer.transform([processed_input]))
        prediction = model.predict(input_vector)[0]
        sentiment = 'positive' if prediction == 'positive' else 'negative'
        st.write(f"Predicted Sentiment: **{sentiment}**")
    else:
        st.write("Please enter a review.")
"""
with open('app.py', 'w') as f:
    f.write(app_code)

# Cell 4: Run Streamlit with ngrok
from pyngrok import ngrok
import subprocess

# Set ngrok authtoken
!ngrok authtoken 2zwhy33I9ElIYpfLPxzwzMwcCZ2_6kPB1GvYwvxpWakwFZbt8
ngrok.kill()
subprocess.Popen(["streamlit", "run", "app.py", "--server.port", "8501"])
public_url = ngrok.connect(8501)
print(f"Streamlit app is live at: {public_url}")
